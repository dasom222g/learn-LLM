{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dasom222g/learn-LLM/blob/main/01_1_RNN_basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KonRRqJvqHZC"
      },
      "source": [
        "## Sequential Data 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1EA8pVnqHZG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = 5  # 입력 벡터의 크기 (각 토큰/단어의 특성 벡터 차원)\n",
        "hidden_size = 10  # 히든 상태 크기\n",
        "sequence_length = 6  # 시퀀스 길이 (토큰이나 단어의 개수)\n",
        "batch_size = 3  # 배치 크기 (한 번에 처리되는 문장/시퀀스의 개수)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5UAONCGqHZI",
        "outputId": "f66ee782-8d67-4542-835a-5dc2b549fb34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# 임의의 입력 데이터 (배치 크기, 시퀀스 길이, 입력 차원)\n",
        "inputs = torch.randn(sequence_length, batch_size, input_size) # 순서 잘못됐는데 하단에서 transpose해줌\n",
        "inputs.shape # 시퀀스 길이, 배치 크기, 입력(임베딩) 차원\n",
        "\n",
        "# 배열의 깊이: n차원 \"텐서\"\n",
        "# 요소의 갯수: n차원 \"벡터\" or 입력 차원"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9O5oIZaLqHZK"
      },
      "source": [
        "## RNN 모델 사용하기 기본\n",
        "\n",
        "RNN 공식문서 : https://pytorch.org/docs/stable/generated/torch.nn.RNN.html\n",
        "\n",
        "데이터의 차원과 모델의 입출력 차원을 주의깊게 확인합시다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYy7C4D7qHZK",
        "outputId": "f7ba8b56-49cb-4584-dd5e-da543f81d4d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: tensor([[[-7.1568e-01,  1.9286e-01,  4.9208e-01,  4.4872e-01,  8.2368e-01,\n",
            "          -1.9171e-01, -5.3505e-01, -4.4872e-01, -1.3475e-01, -5.9510e-01],\n",
            "         [ 6.3350e-02,  2.2056e-01, -3.9921e-01, -5.5007e-01,  1.3412e-01,\n",
            "          -1.1354e-01, -3.8379e-01,  3.0552e-03,  4.4738e-01,  3.2139e-01],\n",
            "         [-8.6666e-01, -1.2599e-01,  7.8862e-01,  4.9334e-01,  7.8039e-01,\n",
            "          -1.3577e-01,  3.3897e-01, -5.8275e-01, -4.9020e-01, -3.3513e-01]],\n",
            "\n",
            "        [[-5.0238e-01,  2.4940e-02,  1.1960e-01,  3.6320e-01,  3.6992e-01,\n",
            "          -1.0578e-01, -3.7739e-02, -4.8493e-02,  3.4798e-01, -5.0073e-01],\n",
            "         [-5.4984e-01,  3.2763e-01,  5.3948e-01,  3.0824e-01,  6.7658e-01,\n",
            "           5.6096e-03, -5.6853e-01, -3.1793e-01, -1.5277e-01, -1.0775e-01],\n",
            "         [-8.7698e-01, -5.9686e-01,  4.6487e-01,  1.7759e-01,  4.4985e-01,\n",
            "          -5.3241e-01,  3.4904e-01,  2.1645e-01, -4.3878e-01, -1.2425e-01]],\n",
            "\n",
            "        [[-6.1331e-01,  3.8120e-02,  2.5483e-01,  5.0383e-01,  7.2624e-01,\n",
            "          -8.0480e-01, -1.5824e-01, -4.4060e-01,  3.4532e-01, -7.8688e-01],\n",
            "         [-1.7850e-01,  2.4534e-01, -1.8843e-01, -4.0692e-04,  2.0742e-01,\n",
            "          -2.4980e-01,  4.2291e-02,  2.7517e-01,  2.7981e-01, -5.5421e-02],\n",
            "         [-2.6732e-01,  5.2235e-01, -5.3058e-01, -1.9946e-01,  5.7804e-01,\n",
            "          -1.6012e-02,  1.6577e-01,  6.2217e-01,  4.2179e-01,  6.7475e-01]],\n",
            "\n",
            "        [[-5.2173e-01, -1.3156e-01, -2.3226e-01,  4.4777e-02,  2.3717e-01,\n",
            "          -6.5470e-01, -9.7579e-02,  3.3755e-01,  4.1867e-01, -1.1362e-01],\n",
            "         [-3.7739e-01,  4.4208e-01,  7.5759e-02,  1.2506e-01,  5.4978e-01,\n",
            "           1.1266e-01, -6.0713e-02,  1.8464e-01,  1.4495e-01,  4.1012e-01],\n",
            "         [-4.8662e-01, -3.9426e-02,  5.0817e-01, -4.1742e-01,  3.8567e-01,\n",
            "           3.8683e-01, -3.4372e-01, -1.8638e-01,  3.2065e-01,  2.2590e-01]],\n",
            "\n",
            "        [[-3.8953e-01,  6.4853e-02,  7.4189e-02, -4.2194e-01,  3.9062e-01,\n",
            "          -6.1260e-02, -4.2297e-01, -1.3331e-01,  7.2612e-01, -1.4127e-03],\n",
            "         [ 2.3816e-01,  2.6148e-01, -5.8892e-01, -5.8201e-01,  6.5992e-02,\n",
            "          -8.3949e-01, -5.1717e-01,  4.4117e-01,  4.6805e-01,  6.8710e-02],\n",
            "         [-3.3809e-01, -2.8591e-02,  3.7689e-01, -1.7768e-01,  3.4507e-01,\n",
            "           2.4297e-01, -6.0681e-02,  1.5534e-01,  1.0905e-01,  3.5943e-01]],\n",
            "\n",
            "        [[-5.0572e-01,  2.5697e-02,  4.3926e-01,  1.5298e-01,  5.1154e-01,\n",
            "          -4.4196e-01, -4.4194e-01,  1.5379e-01,  5.6540e-02,  2.5233e-02],\n",
            "         [-4.5225e-01,  4.2511e-01,  3.5748e-01,  8.7188e-02,  5.6322e-01,\n",
            "          -3.9929e-01,  3.9215e-01, -6.2253e-01,  8.5443e-02,  6.4502e-02],\n",
            "         [-2.4528e-01,  4.3808e-01, -9.4291e-02,  7.0670e-02,  6.9427e-01,\n",
            "          -5.9216e-01, -2.4412e-01,  2.9915e-01,  1.9213e-02,  3.9619e-02]]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "Hidden shape: tensor([[[-0.5057,  0.0257,  0.4393,  0.1530,  0.5115, -0.4420, -0.4419,\n",
            "           0.1538,  0.0565,  0.0252],\n",
            "         [-0.4523,  0.4251,  0.3575,  0.0872,  0.5632, -0.3993,  0.3922,\n",
            "          -0.6225,  0.0854,  0.0645],\n",
            "         [-0.2453,  0.4381, -0.0943,  0.0707,  0.6943, -0.5922, -0.2441,\n",
            "           0.2992,  0.0192,  0.0396]]], grad_fn=<StackBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# RNN 모델\n",
        "rnn = nn.RNN(input_size, hidden_size, batch_first=False)\n",
        "# batch_first=False가 디폴트이므로 생략 가능\n",
        "\n",
        "# RNN 실행\n",
        "# output: 모든 타임스텝에 대한 RNN의 출력 (밖으로 나가는 값)\n",
        "# hidden: 마지막 타임스텝의 히든 상태 (다음 스텝으로 넘어가는 값\n",
        "# output과 hidden의 값은 같음\n",
        "output, hidden = rnn(inputs)\n",
        "\n",
        "print(\"Output shape:\", output)  # (seq_len, batch, hidden_size)\n",
        "print(\"Hidden shape:\", hidden)  # (num_layers, batch, hidden_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkBuQDTSqHZL",
        "outputId": "cc8b4823-28fc-4dd9-b643-b759aac8f45c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: torch.Size([3, 6, 10])\n",
            "Hidden shape: torch.Size([1, 3, 10])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-4.1885e-01,  6.0842e-01,  5.6368e-01,  3.0921e-01,  1.2162e-01,\n",
              "          -1.9593e-01,  4.2528e-01, -3.3651e-01, -5.5549e-01, -2.5051e-01],\n",
              "         [-6.4564e-01,  4.1438e-01,  3.7881e-01,  3.5976e-01,  5.3905e-01,\n",
              "           4.5546e-02,  1.3136e-01, -8.2601e-01, -2.4693e-01,  8.7032e-02],\n",
              "         [-7.7738e-01, -5.1519e-02,  3.6897e-01, -1.4760e-01,  1.8256e-01,\n",
              "           1.8522e-01,  4.0770e-01, -7.9235e-01,  1.4749e-01,  2.5158e-01],\n",
              "         [-5.7527e-01,  1.8924e-01, -3.0826e-01, -3.1468e-01,  3.4373e-01,\n",
              "           7.7289e-02,  3.0908e-01, -5.7196e-01,  3.3536e-02, -1.0096e-02],\n",
              "         [-4.4764e-01,  2.6334e-01,  1.6981e-01,  6.8910e-02,  3.8579e-01,\n",
              "           2.1305e-02,  1.7999e-01, -7.2224e-01, -1.5625e-01,  1.0449e-01],\n",
              "         [-2.6448e-01,  3.1103e-01,  3.0608e-01,  1.7974e-01, -2.7373e-02,\n",
              "           1.9205e-01,  2.5127e-01, -4.7278e-01, -1.7284e-01, -1.4480e-01]],\n",
              "\n",
              "        [[-8.1686e-02,  8.2762e-02, -4.9191e-01, -1.7225e-01,  4.9303e-01,\n",
              "          -1.2664e-01,  2.7832e-01, -7.5760e-01,  4.9328e-02,  4.6455e-01],\n",
              "         [-1.5530e-01,  4.8064e-01,  6.2876e-01,  4.9633e-01, -1.7328e-01,\n",
              "           1.2914e-01,  3.2741e-01, -3.0525e-01, -5.1751e-01, -2.5102e-01],\n",
              "         [-2.3460e-01,  1.5156e-01, -1.0620e-01,  1.6178e-01,  4.4366e-01,\n",
              "           1.9125e-02,  1.1903e-01, -7.6921e-01, -7.8591e-03,  2.9050e-01],\n",
              "         [ 3.0457e-01,  5.5705e-01,  3.9994e-01,  1.6148e-01,  7.8730e-02,\n",
              "           3.1044e-01,  2.0942e-01, -1.4659e-01, -1.8243e-01, -8.2201e-02],\n",
              "         [-5.1856e-01, -4.8561e-01, -8.5483e-01, -4.8247e-01,  5.7686e-01,\n",
              "          -3.5818e-01,  4.2234e-01, -7.1398e-01,  3.6032e-01,  4.7404e-01],\n",
              "         [ 2.7115e-01, -4.2953e-01,  1.6630e-01, -1.4529e-01, -6.0621e-01,\n",
              "           5.9383e-01,  5.0800e-01, -6.8785e-01,  3.0291e-03,  1.7278e-01]],\n",
              "\n",
              "        [[ 8.8440e-02,  2.6973e-01,  6.3385e-01,  6.4047e-01, -6.1987e-01,\n",
              "           9.6279e-02,  3.6227e-01, -4.5881e-01, -5.9607e-01, -2.2474e-01],\n",
              "         [-5.3599e-01,  2.7271e-01,  4.6381e-02,  5.9376e-01,  7.1615e-04,\n",
              "          -2.4839e-01,  1.8396e-02, -4.5021e-01, -6.1836e-01, -4.1219e-01],\n",
              "         [ 3.8537e-01,  4.7802e-01,  4.9782e-02, -3.2443e-01,  4.4204e-01,\n",
              "           3.3613e-01, -4.2088e-02, -1.9523e-01,  1.3101e-02, -1.6916e-01],\n",
              "         [-8.6407e-02,  5.2464e-01,  2.9363e-01,  6.7300e-01,  8.9340e-02,\n",
              "          -2.4019e-01,  2.5360e-01, -5.9741e-01, -3.7460e-01, -5.7600e-03],\n",
              "         [ 1.5449e-02,  3.5103e-01,  5.5948e-01,  5.7524e-01,  1.8138e-01,\n",
              "           3.4712e-01,  3.0449e-03, -7.1893e-01, -2.9172e-01,  2.2446e-01],\n",
              "         [ 6.5827e-02,  2.4100e-01,  6.6298e-02, -4.2762e-03,  5.9818e-02,\n",
              "           1.1096e-01,  3.4074e-01, -3.2920e-01,  1.2516e-01,  1.6910e-01]]],\n",
              "       grad_fn=<TransposeBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "# RNN 모델\n",
        "rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "\n",
        "# RNN 실행\n",
        "# output: 모든 타임스텝에 대한 RNN의 출력\n",
        "# hidden: 마지막 타임스텝의 히든 상태\n",
        "# 마지막 output값과 hidden값은 같음\n",
        "output, hidden = rnn(inputs.transpose(0, 1)) # 6, 3, 5 -> 3, 6, 5\n",
        "\n",
        "print(\"Output shape:\", output.shape)  # (batch_size, sequence_length, hidden_size) -> 3차원 텐서\n",
        "print(\"Hidden shape:\", hidden.shape)  # (num_layers, batch_size, hidden_size)\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 마지막 배치 샘플의 모든 시간 단계와 모든 hidden 차원을 선택\n",
        "output[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-b5TEqU9_uz",
        "outputId": "321b1c78-454f-4fc4-80c8-5c985f0fb053"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.4811,  0.1955, -0.1521,  0.5460, -0.1141, -0.5754, -0.1652,  0.6976,\n",
              "         -0.2336, -0.5983],\n",
              "        [-0.1442, -0.0678,  0.2548, -0.2921, -0.3747, -0.4995,  0.1132,  0.8637,\n",
              "         -0.1424, -0.7099],\n",
              "        [-0.8132, -0.6771,  0.2329,  0.0566, -0.4394, -0.6033,  0.0671, -0.5342,\n",
              "         -0.9211, -0.2553],\n",
              "        [ 0.3065, -0.5189, -0.3251,  0.5928,  0.3215,  0.3675, -0.2593,  0.5227,\n",
              "         -0.5719, -0.0708],\n",
              "        [ 0.5156, -0.3762,  0.0249,  0.0448, -0.3481, -0.5472, -0.3675, -0.0805,\n",
              "         -0.7982, -0.6370],\n",
              "        [-0.5113, -0.5349, -0.0451,  0.3965, -0.2692, -0.1819,  0.4943,  0.1494,\n",
              "         -0.7939,  0.0140]], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 배치에 대해, 마지막 시간 단계의, 모든 hidden 차원을 선택\n",
        "output[:, -1, :]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55hMdBIi9BKs",
        "outputId": "c1821b57-2a31-4273-ee90-5af9ce3bccc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2645,  0.3110,  0.3061,  0.1797, -0.0274,  0.1921,  0.2513, -0.4728,\n",
              "         -0.1728, -0.1448],\n",
              "        [ 0.2712, -0.4295,  0.1663, -0.1453, -0.6062,  0.5938,  0.5080, -0.6879,\n",
              "          0.0030,  0.1728],\n",
              "        [ 0.0658,  0.2410,  0.0663, -0.0043,  0.0598,  0.1110,  0.3407, -0.3292,\n",
              "          0.1252,  0.1691]], grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 층의 최종 은닉 상태\n",
        "hidden[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ImKkuY587iV",
        "outputId": "cea04e95-662b-4800-dbd1-6f9f3ef1a1ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2645,  0.3110,  0.3061,  0.1797, -0.0274,  0.1921,  0.2513, -0.4728,\n",
              "         -0.1728, -0.1448],\n",
              "        [ 0.2712, -0.4295,  0.1663, -0.1453, -0.6062,  0.5938,  0.5080, -0.6879,\n",
              "          0.0030,  0.1728],\n",
              "        [ 0.0658,  0.2410,  0.0663, -0.0043,  0.0598,  0.1110,  0.3407, -0.3292,\n",
              "          0.1252,  0.1691]], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Npg2iy52qHZM"
      },
      "source": [
        "### RNN 모델 학습해보기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XRvPv53qHZN",
        "outputId": "ed0ece8d-45ab-4664-8f08-52c5ad78c3fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/20], Loss: 0.4133\n",
            "Epoch [10/20], Loss: 0.1958\n",
            "Epoch [15/20], Loss: 0.0717\n",
            "Epoch [20/20], Loss: 0.0265\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Hyperparameters\n",
        "## model parameter\n",
        "input_size = 5\n",
        "hidden_size = 10\n",
        "\n",
        "## data parameter\n",
        "sequence_length = 6\n",
        "batch_size = 3\n",
        "num_classes = 2\n",
        "\n",
        "## training parameter\n",
        "learning_rate = 0.01\n",
        "num_epochs = 20\n",
        "\n",
        "# 간단한 RNN 분류 모델\n",
        "# num_classes: output_dim\n",
        "class SimpleRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(SimpleRNN, self).__init__()\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # RNN과 완전연결계층 연결\n",
        "        _, hidden = self.rnn(x)\n",
        "        out = self.fc(hidden[0])  # 마지막 타임스텝의 출력만 사용\n",
        "        return out\n",
        "\n",
        "# 모델, 손실 함수, 옵티마이저 초기화\n",
        "model = SimpleRNN(input_size, hidden_size, num_classes)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 임의의 입력 데이터와 레이블\n",
        "inputs = torch.randn(batch_size, sequence_length, input_size)\n",
        "labels = torch.tensor([0, 1, 0]) # 배치사이즈 3이므로 label도 3개\n",
        "\n",
        "# 학습\n",
        "for epoch in range(num_epochs):\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 5 == 0: # 5바퀴마다\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABnU-M-uqHZO"
      },
      "source": [
        "### multi layer RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAaVl0IiqHZP",
        "outputId": "44db64b5-2098-48c1-edf7-82e65eba54fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: torch.Size([6, 3, 10])\n",
            "Hidden shape: torch.Size([4, 6, 10])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "num_layers = 4 # 층수\n",
        "rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "outputs, hidden = rnn(inputs) # inputs: (batch_size, seq_length, input_size)\n",
        "print(\"Output shape:\", outputs.shape) # (batch_size, seq_length, hidden_size)\n",
        "print(\"Hidden shape:\", hidden.shape) # (num_layers, batch_size, hidden_size)\n",
        "inputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5KVO0ceL_6t",
        "outputId": "5f445e09-74a7-4a87-dee1-34c4b80787cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-6.0321e-02, -1.1036e-01, -3.8680e-01,  4.0996e-01,  1.3605e-01,\n",
              "           1.4679e-01,  3.3409e-01, -3.9453e-01,  1.7790e-01, -5.4677e-02],\n",
              "         [-2.3547e-01, -5.3780e-01, -7.3781e-01,  6.7565e-01, -2.8192e-01,\n",
              "           1.7024e-01,  1.4052e-01, -4.8983e-01, -3.4341e-01,  3.8422e-02],\n",
              "         [-9.9470e-02, -2.7106e-01, -6.7541e-01,  5.1435e-01, -2.6804e-01,\n",
              "          -8.8027e-02,  1.5239e-01, -4.5595e-01, -2.7170e-02, -5.1990e-01]],\n",
              "\n",
              "        [[-4.8150e-02, -1.6367e-01, -3.6468e-01,  4.2031e-01,  6.2057e-02,\n",
              "           2.0494e-01,  3.3399e-01, -3.7709e-01,  8.8626e-02, -7.7415e-02],\n",
              "         [-2.2989e-01, -4.4576e-01, -7.5957e-01,  6.4519e-01, -1.5392e-01,\n",
              "           3.7693e-02,  1.4025e-01, -4.9696e-01, -2.2738e-01,  5.5977e-03],\n",
              "         [-1.6598e-01, -3.1098e-01, -6.8307e-01,  5.8199e-01, -2.9750e-01,\n",
              "           1.5884e-02,  2.0567e-01, -5.0048e-01, -7.2553e-03, -4.6127e-01]],\n",
              "\n",
              "        [[-8.5282e-02, -8.5344e-02, -3.0648e-01,  4.6345e-01,  7.2852e-02,\n",
              "           1.7665e-01,  4.1040e-01, -3.8349e-01,  1.6924e-01, -2.0402e-01],\n",
              "         [-2.0717e-01, -5.2182e-01, -7.0460e-01,  6.4493e-01, -2.6692e-01,\n",
              "           2.7864e-02,  1.8800e-01, -5.4067e-01, -3.6463e-01,  9.5004e-02],\n",
              "         [ 1.9165e-02, -3.4195e-01, -6.9210e-01,  4.4759e-01, -3.5727e-01,\n",
              "          -5.1421e-02, -5.8303e-03, -4.4771e-01, -1.7151e-01, -2.7614e-01]],\n",
              "\n",
              "        [[-6.0228e-02, -1.0214e-01, -3.1826e-01,  4.2957e-01,  6.0410e-02,\n",
              "           1.6376e-01,  3.6378e-01, -3.8577e-01,  1.5321e-01, -1.2823e-01],\n",
              "         [-1.6625e-01, -5.1550e-01, -7.0689e-01,  6.3311e-01, -2.4999e-01,\n",
              "           6.7987e-02,  1.3349e-01, -5.2807e-01, -3.2922e-01,  1.0030e-01],\n",
              "         [-1.3130e-02, -3.6849e-01, -7.3243e-01,  4.5090e-01, -2.9641e-01,\n",
              "           1.3917e-02, -1.2104e-02, -4.2676e-01, -1.5602e-01, -3.0740e-01]],\n",
              "\n",
              "        [[-3.3204e-02, -1.8877e-01, -3.7032e-01,  4.0439e-01,  3.1563e-02,\n",
              "           2.0960e-01,  3.0384e-01, -3.7102e-01,  5.1008e-02, -2.7663e-02],\n",
              "         [-1.8550e-01, -4.3757e-01, -7.1961e-01,  6.2390e-01, -2.4339e-01,\n",
              "           6.2628e-02,  1.1146e-01, -4.5318e-01, -2.6810e-01, -7.1520e-02],\n",
              "         [ 1.7637e-02, -4.1886e-01, -6.2418e-01,  4.6692e-01, -4.0582e-01,\n",
              "           3.8646e-02,  8.2643e-02, -4.4691e-01, -2.4566e-01, -3.9788e-01]],\n",
              "\n",
              "        [[-6.8143e-02, -1.1825e-01, -3.2204e-01,  4.5008e-01,  5.3596e-02,\n",
              "           1.8226e-01,  3.7484e-01, -3.9023e-01,  1.3724e-01, -1.4420e-01],\n",
              "         [-2.3173e-01, -4.7054e-01, -6.5216e-01,  7.0073e-01, -3.1130e-01,\n",
              "           9.1541e-02,  2.8051e-01, -5.2321e-01, -3.1957e-01, -1.7435e-01],\n",
              "         [ 2.2166e-04, -3.2687e-01, -6.0551e-01,  4.7129e-01, -3.9624e-01,\n",
              "          -2.2377e-01,  1.4853e-01, -5.1504e-01, -2.2067e-01, -3.4644e-01]]],\n",
              "       grad_fn=<TransposeBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs[:, -1, :]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORKKt6msJn1O",
        "outputId": "fba33a3d-cde1-494a-d67a-93727659c549"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0780, -0.4109, -0.6987, -0.5977, -0.6827, -0.0499, -0.0374, -0.2129,\n",
              "          0.1733,  0.4696],\n",
              "        [-0.0020, -0.3693, -0.6721, -0.5313, -0.6638, -0.0070, -0.0690, -0.2668,\n",
              "          0.2105,  0.4653],\n",
              "        [-0.0764, -0.4854, -0.7654, -0.6909, -0.6927, -0.1700, -0.0544, -0.1507,\n",
              "          0.1012,  0.4473],\n",
              "        [ 0.1698, -0.3215, -0.6675, -0.5530, -0.6117,  0.0966, -0.1849, -0.2177,\n",
              "          0.2710,  0.5522],\n",
              "        [-0.0141, -0.4239, -0.7258, -0.6475, -0.6878, -0.0706, -0.0863, -0.1808,\n",
              "          0.1743,  0.4917],\n",
              "        [ 0.1054, -0.4292, -0.7287, -0.6091, -0.6273, -0.0515, -0.1865, -0.1488,\n",
              "          0.2054,  0.5665]], grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbtPMIOcJSD_",
        "outputId": "6a793717-62c3-400e-a0c2-f174aaf79a49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.4036,  0.3313,  0.4341, -0.0653, -0.4499, -0.3079,  0.0767, -0.6630,\n",
              "          0.0095,  0.0548],\n",
              "        [ 0.2720,  0.0203, -0.0760,  0.0577, -0.7869, -0.3961,  0.3737,  0.1212,\n",
              "         -0.0698,  0.6628],\n",
              "        [ 0.4125,  0.8248,  0.2614, -0.8441,  0.3923, -0.4826,  0.7592, -0.2425,\n",
              "          0.8120,  0.0971],\n",
              "        [ 0.4810, -0.3693,  0.0860,  0.2265, -0.3943, -0.2195,  0.5495,  0.0157,\n",
              "         -0.0257,  0.4527],\n",
              "        [ 0.2624,  0.3486,  0.3045, -0.3112, -0.0886,  0.0737,  0.0924, -0.4091,\n",
              "          0.5287,  0.1673],\n",
              "        [ 0.0163, -0.1539,  0.1215, -0.2946,  0.1504, -0.6154,  0.2515,  0.3272,\n",
              "          0.5939,  0.0699]], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lD6TSC4DqHZP",
        "outputId": "e20e2d88-ee66-4f14-f651-b859c780c719"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/20], Loss: 0.5117\n",
            "Epoch [10/20], Loss: 0.1344\n",
            "Epoch [15/20], Loss: 0.0332\n",
            "Epoch [20/20], Loss: 0.0134\n"
          ]
        }
      ],
      "source": [
        "class MultiLayerRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(MultiLayerRNN, self).__init__()\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.rnn(x)\n",
        "        out = self.fc(out[:, -1, :]) # 마지막 은닉상태\n",
        "        return out\n",
        "\n",
        "num_layers = 4\n",
        "model = MultiLayerRNN(input_size, hidden_size, num_layers, num_classes)\n",
        "\n",
        "# 모델, 손실 함수, 옵티마이저 초기화\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 임의의 입력 데이터와 레이블\n",
        "inputs = torch.randn(batch_size, sequence_length, input_size)\n",
        "labels = torch.tensor([0, 1, 0])\n",
        "\n",
        "# 학습\n",
        "for epoch in range(num_epochs):\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "El5fx8KuqHZQ"
      },
      "source": [
        "### 양방향 RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQoW7dAOqHZQ",
        "outputId": "c701a213-520d-439a-efad-44fb3ade70ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output shape: torch.Size([3, 6, 20])\n",
            "Hidden shape: torch.Size([8, 3, 10])\n"
          ]
        }
      ],
      "source": [
        "# batch_first=True, bidirectional=True 로 설정하면 양방향\n",
        "rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
        "outputs, hidden = rnn(inputs)\n",
        "\n",
        "# input_size = 5\n",
        "# hidden_size = 10\n",
        "# sequence_length = 6\n",
        "# batch_size = 3\n",
        "# num_layers = 4\n",
        "print(\"Output shape:\", outputs.shape) # (batch_size, seq_length, hidden_size * 2)\n",
        "print(\"Hidden shape:\", hidden.shape) # (num_layers * 2, batch_size, hidden_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Tlf5q6qqHZR"
      },
      "outputs": [],
      "source": [
        "# RNN의 hidden은 첫번째 레이어부터 마지막 레이어까지 forward, backward가 순차적으로 쌓인 것\n",
        "out_forward = outputs[:, -1, :hidden_size]  # forward 방향의 마지막 타임스텝 출력\n",
        "out_backward = outputs[:, 0, hidden_size:]  # backward 방향의 첫 번째 타임스텝 출력 (뒤에서 앞으로)\n",
        "\n",
        "# forward와 backward 방향의 출력을 결합\n",
        "out_combined = torch.cat((out_forward, out_backward), dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRpmQeybqHZT"
      },
      "outputs": [],
      "source": [
        "# 또는 hidden을 이용할 수도 있음\n",
        "#https://stackoverflow.com/questions/63121983/bidirectional-rnn-implementation-pytorch\n",
        "out_combined = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9Easu4ZqHZT",
        "outputId": "a1678e90-9dc2-44f7-c5d7-65ed7be352c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/20], Loss: 2.2887\n",
            "Epoch [10/20], Loss: 1.8511\n",
            "Epoch [15/20], Loss: 1.6225\n",
            "Epoch [20/20], Loss: 1.4792\n"
          ]
        }
      ],
      "source": [
        "class BiDirectionalRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(BiDirectionalRNN, self).__init__()\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_size * 2, num_classes)  # 양방향이므로 Linear에 넣어야 하는 히든 크기가 2배\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, hidden = self.rnn(x)\n",
        "\n",
        "        # hidden[-2,:,:]: forward의 마지막 레이어 마지막 타임스텝 히든 상태\n",
        "        # hidden[-1,:,:]: backward의 마지막 레이어 마지막 타임스텝 히든 상태\n",
        "        out_combined = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)  # 마지막 타임스텝의 출력만 사용\n",
        "        out = self.fc(out_combined)\n",
        "        return out\n",
        "\n",
        "# 모델 초기화 (양방향 설정)\n",
        "model = BiDirectionalRNN(input_size, hidden_size, num_layers=2, num_classes=num_classes)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 임의의 입력 데이터와 레이블\n",
        "inputs = torch.randn(batch_size, sequence_length, input_size)\n",
        "labels = torch.tensor([0, 1, 0])\n",
        "\n",
        "# 학습\n",
        "for epoch in range(num_epochs):\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnDhwN8OqHZU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}